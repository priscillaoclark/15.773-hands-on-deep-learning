{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priscillaoclark/15.773-hands-on-deep-learning/blob/main/HODL_SP25_Recitation_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag Of Words Models for NLP"
      ],
      "metadata": {
        "id": "CkARRNmh0OLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usual technical preliminaries ..."
      ],
      "metadata": {
        "id": "KKyaP5zKQ1iF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHjmcrgSjKfD"
      },
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "keras.utils.set_random_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieving and preparing the data\n"
      ],
      "metadata": {
        "id": "M_e2yrcURl2C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYaoGIaOpo2Z"
      },
      "source": [
        "We will use the FakeNews dataset, which consists of 20800 news articles and a label 0 or 1 depending on whether the articles represent fake news (1) or not (0). Let's first download the data from Google drive."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then load the data and split into train/test and validation sets (we use 50% of the data for training, 25% for validation and 25% for testing) as shown below:"
      ],
      "metadata": {
        "id": "QjhhvmFvjzON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "url = \"https://www.dropbox.com/scl/fi/lxwgznxw5qvjx17pnjztr/Fake_News.csv?rlkey=0mpxsdv43r2jfk6dnd2ku945w&st=q7azv8fg&dl=1\"\n",
        "df = pd.read_csv(url).astype(str)[['text', 'label']]\n"
      ],
      "metadata": {
        "id": "ttiAtLABhq-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_val_df = df.sample(frac=0.5, random_state=42)\n",
        "train_df = df.drop(test_val_df.index)\n",
        "\n",
        "val_df = test_val_df.sample(frac=0.5, random_state=43)\n",
        "test_df = test_val_df.drop(val_df.index)\n",
        "\n",
        "# Get the labels for the train/test/validation sets\n",
        "y_train = train_df['label'].to_numpy().astype(np.float32)\n",
        "y_test = test_df['label'].to_numpy().astype(np.float32)\n",
        "y_val = val_df['label'].to_numpy().astype(np.float32)"
      ],
      "metadata": {
        "id": "TSE9awUp67iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train set shape: {train_df.shape}')\n",
        "print(f'Test set shape: {test_df.shape}')\n",
        "print(f'Validation set shape: {val_df.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToCeTz5_wGs7",
        "outputId": "f3ad1e9e-35e9-4b28-ff27-34ef4442e586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (10400, 2)\n",
            "Test set shape: (5200, 2)\n",
            "Validation set shape: (5200, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the first 5 rows of the training set:"
      ],
      "metadata": {
        "id": "zWNBAOBoxt0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jVDtPZTFkmWl",
        "outputId": "abebbae1-3237-4683-80eb-afd9874d33c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text label\n",
              "1   Ever get the feeling your life circles the rou...     0\n",
              "2   Why the Truth Might Get You Fired October 29, ...     1\n",
              "4   Print \\nAn Iranian woman has been sentenced to...     1\n",
              "9   A week before Michael T. Flynn resigned as nat...     0\n",
              "10  Organizing for Action, the activist group that...     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bf7fd48-308f-43f5-aec1-de7c84ef7fc2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Organizing for Action, the activist group that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bf7fd48-308f-43f5-aec1-de7c84ef7fc2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7bf7fd48-308f-43f5-aec1-de7c84ef7fc2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7bf7fd48-308f-43f5-aec1-de7c84ef7fc2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-92ce8b51-0bb6-4a35-b5c9-e5c803ad9c2f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92ce8b51-0bb6-4a35-b5c9-e5c803ad9c2f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-92ce8b51-0bb6-4a35-b5c9-e5c803ad9c2f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 10400,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10226,\n        \"samples\": [\n          \"WASHINGTON  \\u2014   The White House said on Monday that President Obama would veto legislation approved by Congress that would allow the families of victims of the Sept. 11, 2001, attacks to sue Saudi Arabia for any role in the plot, escalating a bipartisan dispute with lawmakers over the measure. Josh Earnest, the White House press secretary, said Mr. Obama \\u201cdoes intend to veto this legislation,\\u201d and would work to persuade lawmakers in both parties to change course. If he cannot, the measure could lead to the first veto override of his presidency, as the legislation drew the backing of lopsided majorities in both the House and Senate. \\u201cThe president feels quite strongly about this,\\u201d Mr. Earnest said of the legislation, which Mr. Obama has said could dangerously undermine the United States\\u2019 interests globally, opening the country to a raft of lawsuits by private citizens overseas. \\u201cThe concept of sovereign immunity is one that protects the United States as much as any other country in the world,\\u201d Mr. Earnest said, referring to the rationale behind a 1976 law that gives other countries broad immunity from American lawsuits. \\u201cIt\\u2019s not hard to imagine other countries using this law as an excuse to haul U. S. diplomats or U. S. service members, or even U. S. companies, into courts around the world. \\u201d The bill has placed Mr. Obama in an awkward position, pitting him against the grieving families of victims of terrorism and many of his strongest Democratic allies, including in New York\\u2019s congressional delegation. \\u201cThe families of the   victims have suffered so much and fought so hard for justice,\\u201d said Senator Chuck Schumer, Democrat of New York. \\u201cI hope for their sake that the administration will rethink vetoing this bill. \\u201d The legislation would alter that 1976 statute to allow nations to be sued in federal courts if they are found to have played any role in terrorist attacks that killed Americans on United States soil. It also allows Americans to file financial claims against those who funded the attacks. Supported by the families of victims of the Sept. 11 attacks, the measure also reflects a broader   in Washington of the alliance with Saudi Arabia, once an unquestioned partner. The measure passed the Senate in May without opposition, and sailed through the House by a large margin on Friday. It takes a   vote of both the House and Senate to override a veto. The president will lobby lawmakers to change their votes, Mr. Earnest said, including many members he said had privately agreed with Mr. Obama\\u2019s position on the bill, but felt that voting against it would harm their political prospects. \\u201cIn many cases, we had members of Congress who were sympathetic to our concerns, but I think those same members of Congress were concerned about the impact this might have on their political standing, to oppose this bill,\\u201d Mr. Earnest said.\",\n          \"Originally appeared at Nsnbc International \\nAcademy member Boris Chetverushkin, on Friday, stated that former U.S. Secretary of State and Nobel Peace Prize laureate Dr. Henry Kissinger has been elected to the Russian Academy of Sciences along with another six Nobel Prize laureates. \\nThe other Nobel Prize winners elected to the Russian Academy of Sciences include Serge Haroche and Martinus Veltman (physics); Roger D. Kornberg, Jean-Pierre Sauvage and Dan Shechtman (chemistry); Kenneth J. Arrow (economy). Kissinger was also elected to the Academy for his \\u201cglobal studies\\u201d. \\nThe now 93-year-old Dr. Henry Kissinger, 93, is one of the authors of the policy of \\u2018d\\u00b7tente\\u201d in the US-Soviet relations. In 1993 he won the Nobel Peace Prize for his role in negotiating and reaching the Paris Accord aimed at ending the war against / in Vietnam. Kissinger also has many US State awards, including the Presidential Medal of Freedom, the highest US civilian decoration, awarded to individuals who have made an outstanding contribution to the security or national interests of the United States, world peace, cultural or other significant public or private endeavors. \\nIn latter years after withdrawing from \\u201cofficial\\u201d politics, Kissinger promoted the image that he now was focusing on \\u201cwriting memoirs\\u201d, articles, books on foreign policy and diplomacy, including his works \\u201cNuclear Weapons and Foreign Policy\\u201d; \\u201cThe White House Years\\u201d and \\u201cDoes America Need a Foreign Policy?\\u201d \\nDuring the onset of the crisis in Ukraine Kissinger also wrote a lengthy article suggesting the \\u201cFinlandization\\u201d of the Ukraine, but without mentioning a word about the systematic engineering of the \\u201ccrisis\\u201d by U.S. power-brokers. Kissinger may or may not have stopped being a \\u201cswinger\\u201d, but as he once said, \\u201cpower is the ultimate aphrodisiac\\u201d. He may have withdrawn from \\u201cofficial\\u201d politics but he never removed himself far from \\u201cpower\\u201d. \\nWhen the administration of George W. Bush had to cave in to pressure to launch an investigation into the events on September 11, 2001, it suggested that Dr. Henry Kissinger lead the 9/11 Commission. Kissinger had to withdraw when some of the bereaved \\u201cJersey Girls\\u201d asked Kissinger if his company, by any chance, had members of the Bin Laden family among its clients. An actual \\u201ccriminal\\u201d investigation into 9/11 took never place and leading members of the 9/11 Commission have since written that it was \\u201cset up to fail\\u201d from the start. \\nIronically, Kissinger has also been one of the main architects of the U.S. policy that led to the bloody coup in Chile, on September 11, 1973. A coup that inspired many then young people (like this author) in Latin America and in the West to organize a militant resistance. The overthrow of Salvador Allende was followed by sixteen years of terror. \\nKissinger also played key roles in Argentina\\u2019s \\u201cdirty war\\u201d, marked by mass\\u201cdisappearances\\u201d with bodies of \\u201cdissidents\\u201d dumped into the ocean from helicopters, dumped into mass graves, and many of those who lived to tell the tale were marked by the trauma of physical and psychological torture for the remainder of their lives. \\nThe U.S. \\u201cpolicy\\u201d, in Latin America, of which Kissinger was a main architect, would also spill over into, and spill blood in Colombia, Venezuela, Guatemala, Honduras, El Salvador and Nicaragua. \\nDr. Kissinger\\u2019s \\u201crap sheet\\u201d is far too long to publish in one news article, but one may want to read the book of the late journalist Christopher Hitchens wrote about Kissinger in his book entitled \\u201cThe Trial of Henry Kissinger\\u201d. \\nHitchens diligently documented Kissinger\\u2019s involvement in a number of alleged war crimes in Indochina (Vietnam \\u2013 Laos \\u2013 Cambodia), Bangladesh, Chile, Cyprus and East Timor. Hitchens made a compelling case for the need to prosecute Dr. Henry Kissinger. \\nThe Russian Academy of Sciences, for its part, has arguably made two brilliant points by electing Kissinger. It has provided additional evidence for the fact that Academies of Science, worldwide, are instruments of politicized science comparable to a Caliphate being a marriage of State and religion. It has also proven that utilitarianism at the Russian Academy of Sciences outweighs scientific, moral and ethical imperatives.\",\n          \"Evelyn Farkas, a former top Obama administration official, has denied that she had access to inside information when she made remarks as a contributor to MSNBC last month that seemed to acknowledge efforts by members of the Obama administration to collect intelligence on Donald Trump and members of his 2016 presidential campaign. [However, the news media has largely failed to note that on February 16, about two weeks prior to her statements on MSNBC, Farkas revealed in an interview that she was \\u201cgetting winks and hints from inside that there was something really wrong here\\u201d  \\u2014   referring to Trump officials\\u2019 alleged ties to Russia.  She stated that she was \\u201cfirst made aware of all this stuff\\u201d during the summer.  On March 2, Farkas stated on MSNBC that she told former Obama administration colleagues to collect intelligence on Trump and campaign officials. \\u201cI was urging my former colleagues and, frankly speaking, the people on the Hill, it was more actually aimed at telling the Hill people, get as much information as you can, get as much intelligence as you can, before President Obama leaves the administration,\\u201d stated Farkas. She continued: Because I had a fear that somehow that information would disappear with the senior [Obama] people who left, so it would be hidden away in the bureaucracy   \\u2026     that the Trump folks  \\u2014   if they found out how we knew what we knew about their   \\u2026     the Trump staff dealing with Russians  \\u2014   that they would try to compromise those sources and methods, meaning we no longer have access to that intelligence. After her remarks resurfaced and were subsequently used by the White House to bolster the charge that Trump was under illicit surveillance during the campaign, Farkas gave interviews denying that she had any inside information when she made those comments to MSNBC. She told the Daily Caller last week that she had no access to any intelligence. \\u201cI had no intelligence whatsoever, I wasn\\u2019t in government anymore and didn\\u2019t have access to any,\\u201d she said. Speaking to the Washington Post, Farkas denied being a source of any leaks. The Post reported: Farkas, in an interview with The Post, said she \\u201cdidn\\u2019t give anybody anything except advice,\\u201d was not a source for any stories and had nothing to leak. Noting that she left government in October 2015, she said, \\u201cI was just watching like anybody else, like a regular spectator\\u201d as initial reports of Russia contacts began to surface after the election. However, on February 16, Farkas told Ezra Klein at Vox. com that she was \\u201cgetting winks and hints from inside\\u201d about alleged Russia ties.  The interview was also highlighted by the Gateway Pundit blog. Farkas was asked by Klein about her \\u201clevel of alarm after the resignation of Michael Flynn,\\u201d who stepped down in February as Trump\\u2019s national security adviser. Regarding her \\u201clevel of alarm,\\u201d Farkas replied: It\\u2019s lower than it\\u2019s been since the summer, when I was first made aware of all this stuff. I\\u2019m like, finally, everybody else sees it! Seriously. The reason I was so upset last summer was that I was getting winks and hints from inside that there was something really wrong here. I was agitated because I knew the Clinton campaign and the world didn\\u2019t know. But I didn\\u2019t think it would happen this fast. I didn\\u2019t think Flynn would survive a year, but I thought it would be most of the year. The fact that Flynn is gone is constructive from the perspective of US foreign policy. He was getting it wrong on combating terrorism and Russia. So I feel relieved that he will not be whispering his policy prescriptions in the president\\u2019s ear. On the bigger issue, the intelligence community, the bureaucracy, patriotic Americans, and some members of Congress are making it impossible for the White House to sweep whatever they are trying to hide under the rug. And the White House is clearly trying to hide something, or the president would have said, on day one, that he would support the investigations that began under his predecessor. This past week, Breitbart News first reported that at a conference last October, held two weeks before the presidential election, Farkas predicted that if Trump won the presidency he would \\u201cbe impeached pretty quickly or somebody else would have to take over government. \\u201d Breitbart News also first reported that at the same conference, Farkas warned that more must be done to counter the forces of nationalism and populism that have been entering the mainstream with the rise of Trump and nationalist movements across Europe. Farkas currently serves as a nonresident senior fellow at the Atlantic Council, which takes a hawkish approach toward Russia and has released numerous reports and briefs about Russian aggression. The Council is funded by the Rockefeller Brothers Fund, Inc. the U. S. State Department and NATO ACT. Another Council funder is the Ploughshares Fund, which in turn has received financing from billionaire George Soros\\u2019 Open Society Foundations. Farkas serves on the Atlantic Council alongside Dmitri Alperovitch,   of CrowdStrike, the   company utilized by the FBI to make its assessment about alleged Russian hacking into the Democratic National Committee (DNC). Alperovitch is a nonresident senior fellow of the Cyber Statecraft Initiative at the Atlantic Council. Last month, FBI Director James Comey confirmed that his agency never had direct access to the DNC\\u2019s servers to confirm the hacking. \\u201cWell, we never got direct access to the machines themselves,\\u201d he stated. \\u201cThe DNC in the spring of 2016 hired a firm that ultimately shared with us their forensics from their review of the system. \\u201d National Security Agency Director Michael Rogers also stated the NSA never asked for access to the DNC hardware: \\u201cThe NSA didn\\u2019t ask for access. That\\u2019s not in our job. \\u201d  Aaron Klein is Breitbart\\u2019s Jerusalem bureau chief and senior investigative reporter. He is a New York Times bestselling author and hosts the popular weekend talk radio program, \\u201cAaron Klein Investigative Radio. \\u201d Follow him on Twitter @AaronKleinShow. Follow him on Facebook. With research by Joshua Klein.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this colab, we will apply the Bag-Of-Words method for converting every news article into a numerical representation (vector) that can be passed throught a neural network. Then, we will create a neural network to classify the articles into `fake news` or `not fake news`.\n",
        "\n",
        "We will begin by applying the STIE process into our articles."
      ],
      "metadata": {
        "id": "ngUWi0rd3RZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-hot encoding: Unigrams"
      ],
      "metadata": {
        "id": "AlVU28qhety8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The STIE process we described - Standardize, Tokenize, Index, and Encode - ....\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "... is implemented by the `TextVectorization` layer. You can check out the documentation of `TextVectorization` [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization).\n",
        "\n",
        "We first configure the layer by telling it what S, T, I, and E we want.\n",
        "\n",
        "In our first example,\n",
        "- we use the default standarization which will remove punctuation and covert to lowercase.\n",
        "- we use the default tokenization at a word level, by setting `split='whitespace'`.\n",
        "- we set the output mode to `multi_hot`"
      ],
      "metadata": {
        "id": "Jp_oqymHZxai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we set up our Text Vectorization layer using multi-hot encoding\n",
        "\n",
        "max_tokens = 5000 # size of vocabulary space\n",
        "text_vectorization = keras.layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    ngrams=None, # default is 1 (1 word at a time)\n",
        "    standardize='lower_and_strip_punctuation', # default\n",
        "    split='whitespace', # default\n",
        "    output_mode=\"multi_hot\", # can also be count\n",
        ")\n",
        "\n",
        "text_vectorization.adapt(train_df['text'])"
      ],
      "metadata": {
        "id": "rXYSppAQ0H5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.get_vocabulary()[:20] # ordered by frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEtF7guI1UUu",
        "outputId": "db376374-fdba-4206-99a7-0774be12144d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[UNK]',\n",
              " 'the',\n",
              " 'to',\n",
              " 'of',\n",
              " 'and',\n",
              " 'a',\n",
              " 'in',\n",
              " 'that',\n",
              " 'is',\n",
              " 'for',\n",
              " 'on',\n",
              " 'was',\n",
              " 'with',\n",
              " 'it',\n",
              " 'as',\n",
              " 'he',\n",
              " 'said',\n",
              " 'by',\n",
              " 'are',\n",
              " 'at']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then vectorize the train/test/validation sets using multi-hot encoding."
      ],
      "metadata": {
        "id": "-HXL_1jPcJRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#apply function to get multihot encodings\n",
        "X_train = text_vectorization(train_df['text'])\n",
        "X_val = text_vectorization(val_df['text'])\n",
        "X_test = text_vectorization(test_df['text'])"
      ],
      "metadata": {
        "id": "Tf8boeYzcHAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the `X_train` dataframe looks like:"
      ],
      "metadata": {
        "id": "3irUTBuqyUw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_train, columns=text_vectorization.get_vocabulary()).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "T287I2_Yx5_C",
        "outputId": "24b94d9c-a14f-46a6-a23a-9837edbfc9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       [UNK]  the  to  of  and  a  in  that  is  for  ...  warnings  wanting  \\\n",
              "0          1    1   1   1    1  1   1     1   1    1  ...         0        0   \n",
              "1          1    1   1   1    1  1   1     1   1    1  ...         0        0   \n",
              "2          1    1   1   1    1  1   1     1   1    1  ...         0        0   \n",
              "3          1    1   1   1    1  1   1     1   1    1  ...         0        1   \n",
              "4          1    1   1   1    1  1   1     1   1    1  ...         0        0   \n",
              "...      ...  ...  ..  ..  ... ..  ..   ...  ..  ...  ...       ...      ...   \n",
              "10395      1    1   1   1    1  1   1     1   1    1  ...         0        0   \n",
              "10396      1    1   1   1    1  1   1     1   1    1  ...         0        0   \n",
              "10397      1    1   1   1    1  1   1     1   1    1  ...         0        0   \n",
              "10398      1    1   1   1    1  1   1     1   1    1  ...         0        0   \n",
              "10399      1    1   1   1    1  1   1     1   1    1  ...         0        0   \n",
              "\n",
              "       treating  sugar  successor  states  southeast  sounded  singing  \\\n",
              "0             0      0          0        0          0        0        0   \n",
              "1             0      0          0        0          0        0        0   \n",
              "2             0      0          0        0          0        0        0   \n",
              "3             0      0          0        0          0        0        0   \n",
              "4             0      0          0        0          0        0        0   \n",
              "...         ...    ...        ...      ...        ...      ...      ...   \n",
              "10395         0      0          0        0          0        0        0   \n",
              "10396         0      0          0        0          0        0        0   \n",
              "10397         0      0          0        0          0        0        0   \n",
              "10398         0      0          0        0          0        0        0   \n",
              "10399         0      0          0        0          0        0        0   \n",
              "\n",
              "       shifts  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "...       ...  \n",
              "10395       0  \n",
              "10396       0  \n",
              "10397       0  \n",
              "10398       0  \n",
              "10399       0  \n",
              "\n",
              "[10400 rows x 5000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc683535-bfcb-491f-a19c-8f49c0a50d53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>[UNK]</th>\n",
              "      <th>the</th>\n",
              "      <th>to</th>\n",
              "      <th>of</th>\n",
              "      <th>and</th>\n",
              "      <th>a</th>\n",
              "      <th>in</th>\n",
              "      <th>that</th>\n",
              "      <th>is</th>\n",
              "      <th>for</th>\n",
              "      <th>...</th>\n",
              "      <th>warnings</th>\n",
              "      <th>wanting</th>\n",
              "      <th>treating</th>\n",
              "      <th>sugar</th>\n",
              "      <th>successor</th>\n",
              "      <th>states</th>\n",
              "      <th>southeast</th>\n",
              "      <th>sounded</th>\n",
              "      <th>singing</th>\n",
              "      <th>shifts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10395</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10396</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10397</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10398</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10399</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10400 rows  5000 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc683535-bfcb-491f-a19c-8f49c0a50d53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc683535-bfcb-491f-a19c-8f49c0a50d53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc683535-bfcb-491f-a19c-8f49c0a50d53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14f927d1-b80b-4f9f-aaa2-2993ea1b5544\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14f927d1-b80b-4f9f-aaa2-2993ea1b5544')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14f927d1-b80b-4f9f-aaa2-2993ea1b5544 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize an NN with 1 hidden layer of 8 ReLU neurons and 1 output node with sigmoid activation (i.e. remember we are doing **binary** classification)."
      ],
      "metadata": {
        "id": "RX5SN8i0cgMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Each vector is of length 5000\n",
        "#Each training example is a row of the table above.\n",
        "\n",
        "inputs = keras.layers.Input(shape=(max_tokens, ), name='input')\n",
        "x = keras.layers.Dense(8, activation=\"relu\", name='hidden')(inputs)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\", name='output')(x)\n",
        "bow_model = keras.Model(inputs, outputs, name='simple_bow')\n",
        "\n",
        "bow_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "6GAA731G36J_",
        "outputId": "206a95e1-df90-412c-ec8e-68312b50d702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"simple_bow\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"simple_bow\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input (\u001b[38;5;33mInputLayer\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)                               \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " hidden (\u001b[38;5;33mDense\u001b[0m)                        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                             \u001b[38;5;34m40,008\u001b[0m \n",
              "\n",
              " output (\u001b[38;5;33mDense\u001b[0m)                        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                                  \u001b[38;5;34m9\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">40,008</span> \n",
              "\n",
              " output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,017\u001b[0m (156.32 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,017</span> (156.32 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,017\u001b[0m (156.32 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,017</span> (156.32 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model on the training set\n",
        "bow_model.fit(x=X_train, y=y_train,\n",
        "          validation_data=(X_val, y_val),\n",
        "          epochs=10,\n",
        "          batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CalMI-f4Nio",
        "outputId": "331dac7f-b908-4da1-c900-dc58a2f49dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8478 - loss: 0.3907 - val_accuracy: 0.9742 - val_loss: 0.0999\n",
            "Epoch 2/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9836 - loss: 0.0698 - val_accuracy: 0.9775 - val_loss: 0.0744\n",
            "Epoch 3/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0284 - val_accuracy: 0.9762 - val_loss: 0.0694\n",
            "Epoch 4/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0143 - val_accuracy: 0.9763 - val_loss: 0.0691\n",
            "Epoch 5/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0085 - val_accuracy: 0.9762 - val_loss: 0.0708\n",
            "Epoch 6/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0055 - val_accuracy: 0.9760 - val_loss: 0.0734\n",
            "Epoch 7/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0039 - val_accuracy: 0.9760 - val_loss: 0.0762\n",
            "Epoch 8/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0028 - val_accuracy: 0.9756 - val_loss: 0.0794\n",
            "Epoch 9/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0022 - val_accuracy: 0.9756 - val_loss: 0.0825\n",
            "Epoch 10/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0017 - val_accuracy: 0.9752 - val_loss: 0.0855\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d77adae3c50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Accuracy is', bow_model.evaluate(X_test, y_test)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JeIf8LN4X6f",
        "outputId": "f5970588-69b8-4e4a-a3f1-1cb4b5c9e7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m163/163\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.0673\n",
            "Test Accuracy is 0.9803845882415771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-hot encoding: Bigrams"
      ],
      "metadata": {
        "id": "Iz-OwO9Vf8dF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now try the exact same process but by using Bigrams (looking at pairs of words) instead of just Unigrams."
      ],
      "metadata": {
        "id": "rXQw5V2mfkhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization_with_bigram = keras.layers.TextVectorization(\n",
        "    ngrams=2, # This parameter determines that we want to use Bigrams\n",
        "    max_tokens=20000, # We increase the maximum number of tokens to include bigrams\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    output_mode=\"multi_hot\"\n",
        ")\n",
        "\n",
        "text_vectorization_with_bigram.adapt(train_df['text'])\n",
        "\n",
        "# Use the text_vectorization layer to vectorize the train/test/validation set\n",
        "X_train_bigram = text_vectorization_with_bigram(train_df['text'])\n",
        "X_val_bigram = text_vectorization_with_bigram(val_df['text'])\n",
        "X_test_bigram = text_vectorization_with_bigram(test_df['text'])"
      ],
      "metadata": {
        "id": "StrIJycxfZgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization_with_bigram.get_vocabulary()[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDhCzsJwgGYy",
        "outputId": "96416433-68fe-418c-9759-a7736ad74b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[UNK]',\n",
              " 'the',\n",
              " 'to',\n",
              " 'of',\n",
              " 'and',\n",
              " 'a',\n",
              " 'in',\n",
              " 'that',\n",
              " 'is',\n",
              " 'for',\n",
              " 'on',\n",
              " 'was',\n",
              " 'with',\n",
              " 'it',\n",
              " 'as',\n",
              " 'of the',\n",
              " 'he',\n",
              " 'said',\n",
              " 'by',\n",
              " 'in the']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now create a neural network and fit it into our training set. Note that we use exactly the same NN as before, and the only change is in the size of the input layer."
      ],
      "metadata": {
        "id": "28du7nhOjoH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model (same as before)\n",
        "inputs = keras.layers.Input(shape=(20000, ))\n",
        "x = keras.layers.Dense(8, activation=\"relu\")(inputs)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_bigram = keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model using binary_crossentropy\n",
        "model_bigram.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model on the training set\n",
        "model_bigram.fit(x=X_train_bigram, y=y_train,\n",
        "          validation_data=(X_val_bigram, y_val),\n",
        "          epochs=10,\n",
        "          batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILKUBJ6Rg75E",
        "outputId": "4752aa07-2ba9-4975-8243-df682b54ad59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7881 - loss: 0.5300 - val_accuracy: 0.9694 - val_loss: 0.3218\n",
            "Epoch 2/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.2835 - val_accuracy: 0.9717 - val_loss: 0.2503\n",
            "Epoch 3/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.2085 - val_accuracy: 0.9712 - val_loss: 0.2093\n",
            "Epoch 4/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.1627 - val_accuracy: 0.9740 - val_loss: 0.1774\n",
            "Epoch 5/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.1303 - val_accuracy: 0.9758 - val_loss: 0.1535\n",
            "Epoch 6/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.1060 - val_accuracy: 0.9763 - val_loss: 0.1355\n",
            "Epoch 7/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0874 - val_accuracy: 0.9763 - val_loss: 0.1210\n",
            "Epoch 8/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9997 - loss: 0.0727 - val_accuracy: 0.9775 - val_loss: 0.1100\n",
            "Epoch 9/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0609 - val_accuracy: 0.9783 - val_loss: 0.1011\n",
            "Epoch 10/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0514 - val_accuracy: 0.9788 - val_loss: 0.0947\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d77b36ddad0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now evaluate the accuracy on the test set."
      ],
      "metadata": {
        "id": "nyHmww0sj9bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Accuracy is', model_bigram.evaluate(X_test_bigram, y_test)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBxULSp-hKnC",
        "outputId": "4955ea73-6f91-46a8-ad5b-774c9a1be1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m163/163\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9810 - loss: 0.0901\n",
            "Test Accuracy is 0.9811538457870483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count encoding: Bigrams"
      ],
      "metadata": {
        "id": "qouKZL_QiNyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we just change the type of word encoding we use from **multi-hot** to **count**. Hence, now we are not only interested in whether a token occurs in the text or not, but we are also interested in how many times it occurs."
      ],
      "metadata": {
        "id": "cEEu2o06iVkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization_count = keras.layers.TextVectorization(\n",
        "    ngrams=2, # This indicates that we want to use bigrams\n",
        "    max_tokens=20000,\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    output_mode=\"count\" # THIS is the only parameter we have changed\n",
        "    )\n",
        "\n",
        "text_vectorization_count.adapt(train_df['text'])\n",
        "\n",
        "# Use the text_vectorization layer to vectorize the train/test/validation set\n",
        "X_train_count = text_vectorization_count(train_df['text'])\n",
        "X_val_count = text_vectorization_count(val_df['text'])\n",
        "X_test_count = text_vectorization_count(test_df['text'])\n",
        "\n",
        "pd.DataFrame(X_train_count, columns=text_vectorization_count.get_vocabulary())"
      ],
      "metadata": {
        "id": "3m3xGezEiRX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a0bae785-e899-4f6f-cea5-89e98ecc767b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       [UNK]  the  to  of  and   a  in  that  is  for  ...  has kept  harvest  \\\n",
              "0        548   49  17  18   15  17  15    11   6    9  ...         0        0   \n",
              "1        907   82  36  39   31  21  16    23  19   17  ...         0        0   \n",
              "2        125    9   6   6    2   9   1     3   2    3  ...         0        0   \n",
              "3       1097   83  50  27   34  68  52    18  11   16  ...         0        0   \n",
              "4       1172   82  51  30   27  30  20    29  15   14  ...         0        0   \n",
              "...      ...  ...  ..  ..  ...  ..  ..   ...  ..  ...  ...       ...      ...   \n",
              "10395    303   18  12   9   10  10  11     3   3    7  ...         0        0   \n",
              "10396    453   47  23  20   19  11  13     8   5    6  ...         0        0   \n",
              "10397    243   29  16  13    5   9   2    10   4    4  ...         0        0   \n",
              "10398    601   46  22  29   16  25  11     9   7    8  ...         0        0   \n",
              "10399    976   54  19  28   47  22  11     7  24   19  ...         0        0   \n",
              "\n",
              "       had tried  had called  groups to  greenhouse  government but  get an  \\\n",
              "0              0           0          0           0               0       0   \n",
              "1              1           0          0           0               0       0   \n",
              "2              0           0          0           0               0       0   \n",
              "3              0           0          0           0               0       0   \n",
              "4              0           0          0           0               0       0   \n",
              "...          ...         ...        ...         ...             ...     ...   \n",
              "10395          0           0          0           0               0       0   \n",
              "10396          0           0          0           0               0       0   \n",
              "10397          0           0          0           0               0       0   \n",
              "10398          0           0          0           0               0       0   \n",
              "10399          0           0          0           0               0       0   \n",
              "\n",
              "       george bush  game in  \n",
              "0                0        0  \n",
              "1                0        0  \n",
              "2                0        0  \n",
              "3                0        0  \n",
              "4                0        0  \n",
              "...            ...      ...  \n",
              "10395            0        0  \n",
              "10396            0        0  \n",
              "10397            0        0  \n",
              "10398            0        0  \n",
              "10399            0        0  \n",
              "\n",
              "[10400 rows x 20000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebd0a3e4-ee3e-4d84-896e-cee7e1bedbe6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>[UNK]</th>\n",
              "      <th>the</th>\n",
              "      <th>to</th>\n",
              "      <th>of</th>\n",
              "      <th>and</th>\n",
              "      <th>a</th>\n",
              "      <th>in</th>\n",
              "      <th>that</th>\n",
              "      <th>is</th>\n",
              "      <th>for</th>\n",
              "      <th>...</th>\n",
              "      <th>has kept</th>\n",
              "      <th>harvest</th>\n",
              "      <th>had tried</th>\n",
              "      <th>had called</th>\n",
              "      <th>groups to</th>\n",
              "      <th>greenhouse</th>\n",
              "      <th>government but</th>\n",
              "      <th>get an</th>\n",
              "      <th>george bush</th>\n",
              "      <th>game in</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>548</td>\n",
              "      <td>49</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>907</td>\n",
              "      <td>82</td>\n",
              "      <td>36</td>\n",
              "      <td>39</td>\n",
              "      <td>31</td>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>125</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1097</td>\n",
              "      <td>83</td>\n",
              "      <td>50</td>\n",
              "      <td>27</td>\n",
              "      <td>34</td>\n",
              "      <td>68</td>\n",
              "      <td>52</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1172</td>\n",
              "      <td>82</td>\n",
              "      <td>51</td>\n",
              "      <td>30</td>\n",
              "      <td>27</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>29</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10395</th>\n",
              "      <td>303</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10396</th>\n",
              "      <td>453</td>\n",
              "      <td>47</td>\n",
              "      <td>23</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10397</th>\n",
              "      <td>243</td>\n",
              "      <td>29</td>\n",
              "      <td>16</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10398</th>\n",
              "      <td>601</td>\n",
              "      <td>46</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10399</th>\n",
              "      <td>976</td>\n",
              "      <td>54</td>\n",
              "      <td>19</td>\n",
              "      <td>28</td>\n",
              "      <td>47</td>\n",
              "      <td>22</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>24</td>\n",
              "      <td>19</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10400 rows  20000 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebd0a3e4-ee3e-4d84-896e-cee7e1bedbe6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ebd0a3e4-ee3e-4d84-896e-cee7e1bedbe6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ebd0a3e4-ee3e-4d84-896e-cee7e1bedbe6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b6efb1ab-8e3f-44f5-93bf-eb676a0b6607\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6efb1ab-8e3f-44f5-93bf-eb676a0b6607')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b6efb1ab-8e3f-44f5-93bf-eb676a0b6607 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We again initialize and train the neural network exactly as before."
      ],
      "metadata": {
        "id": "-XjEwePtkGxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model (same as before)\n",
        "inputs = keras.layers.Input(shape=(20000, ))\n",
        "x = keras.layers.Dense(8, activation=\"relu\")(inputs)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_count = keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model using binary_crossentropy\n",
        "model_count.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model on the training set\n",
        "model_count.fit(x=X_train_count, y=y_train,\n",
        "          validation_data=(X_val_count, y_val),\n",
        "          epochs=10,\n",
        "          batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gCjoEjAjZVV",
        "outputId": "425e7acb-ec49-4cf9-8f56-e1c7f86778d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8213 - loss: 0.5705 - val_accuracy: 0.9715 - val_loss: 0.1295\n",
            "Epoch 2/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9822 - loss: 0.0899 - val_accuracy: 0.9771 - val_loss: 0.0898\n",
            "Epoch 3/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9954 - loss: 0.0401 - val_accuracy: 0.9785 - val_loss: 0.0822\n",
            "Epoch 4/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0196 - val_accuracy: 0.9783 - val_loss: 0.0797\n",
            "Epoch 5/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9938 - loss: 0.0363 - val_accuracy: 0.9763 - val_loss: 0.0811\n",
            "Epoch 6/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0075 - val_accuracy: 0.9775 - val_loss: 0.0808\n",
            "Epoch 7/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9999 - loss: 0.0046 - val_accuracy: 0.9790 - val_loss: 0.0808\n",
            "Epoch 8/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 0.0035 - val_accuracy: 0.9788 - val_loss: 0.0845\n",
            "Epoch 9/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0028 - val_accuracy: 0.9787 - val_loss: 0.0904\n",
            "Epoch 10/10\n",
            "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 0.0024 - val_accuracy: 0.9788 - val_loss: 0.0950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d77b36e5ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now evaluate the performance in the test set."
      ],
      "metadata": {
        "id": "ElljKhjEkfhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Accuracy is', model_count.evaluate(X_test_count, y_test)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG2sDCtfkWZn",
        "outputId": "6ab944fc-c67b-411e-e040-ecd97782fd7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m163/163\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9770 - loss: 0.0797\n",
            "Test Accuracy is 0.9796153903007507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary"
      ],
      "metadata": {
        "id": "x381IP5L9swS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Multi + Unigrams Test Accuracy: 97.9%\n",
        "* Multi + Bigrams Test Accuracy: 98.1%\n",
        "* Count + Unigrams Test Accuracy: 97.6%"
      ],
      "metadata": {
        "id": "qx6PuH8N9ueW"
      }
    }
  ]
}